
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>强强联合! 利用 Microsoft Azure AKS 集群集成 Apache Spark 来做大数据计算 | 茶包哥的迷你仓</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. Azure Kubernetes Service 及 Apache Spark 简介伴随着 Kubernetes 技术的日渐成熟和社区生态的蓬勃发展, 越来越多的客户都将自己很多的应用程序迁移到容器服务上, 以便能够设计出更加快速、便捷、更高可靠的应用架构. 为了提高 Kubernetes 集群的部署速度以及降低其运维成本, Microsoft Azure 推出了托管的 Kubernetes">
<meta property="og:type" content="article">
<meta property="og:title" content="强强联合! 利用 Microsoft Azure AKS 集群集成 Apache Spark 来做大数据计算">
<meta property="og:url" content="https://theodorew.github.io/wxsblog.github.io/2019/10/13/2019-10-13-SparkonAKS/index.html">
<meta property="og:site_name" content="茶包哥的迷你仓">
<meta property="og:description" content="1. Azure Kubernetes Service 及 Apache Spark 简介伴随着 Kubernetes 技术的日渐成熟和社区生态的蓬勃发展, 越来越多的客户都将自己很多的应用程序迁移到容器服务上, 以便能够设计出更加快速、便捷、更高可靠的应用架构. 为了提高 Kubernetes 集群的部署速度以及降低其运维成本, Microsoft Azure 推出了托管的 Kubernetes">
<meta property="og:locale">
<meta property="article:published_time" content="2019-10-13T02:23:32.000Z">
<meta property="article:modified_time" content="2020-09-02T16:29:26.000Z">
<meta property="article:author" content="Xinsheng Wang">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="Microsoft Azure">
<meta property="article:tag" content="Kubernetes">
<meta property="article:tag" content="Bigdata">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="茶包哥的迷你仓" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/wxsblog.github.io/css/style.css">

  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
<meta name="generator" content="Hexo 6.0.0"></head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/wxsblog.github.io/" id="logo">茶包哥的迷你仓</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/wxsblog.github.io/">Home</a>
        
          <a class="main-nav-link" href="/wxsblog.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="theodorew.github.io/wxsblog.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main"><article id="post-2019-10-13-SparkonAKS" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/wxsblog.github.io/2019/10/13/2019-10-13-SparkonAKS/" class="article-date">
  <time datetime="2019-10-13T02:23:32.000Z" itemprop="datePublished">2019-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/wxsblog.github.io/categories/Microsoft-Azure/">Microsoft Azure</a>►<a class="article-category-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/">Kubernetes</a>►<a class="article-category-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/">Bigdata</a>►<a class="article-category-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      强强联合! 利用 Microsoft Azure AKS 集群集成 Apache Spark 来做大数据计算
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-Azure-Kubernetes-Service-及-Apache-Spark-简介"><a href="#1-Azure-Kubernetes-Service-及-Apache-Spark-简介" class="headerlink" title="1. Azure Kubernetes Service 及 Apache Spark 简介"></a>1. Azure Kubernetes Service 及 Apache Spark 简介</h2><p>伴随着 Kubernetes 技术的日渐成熟和社区生态的蓬勃发展, 越来越多的客户都将自己很多的应用程序迁移到容器服务上, 以便能够设计出更加快速、便捷、更高可靠的应用架构. 为了提高 Kubernetes 集群的部署速度以及降低其运维成本, Microsoft Azure 推出了托管的 Kubernetes 服务 —— Azure Kubernetes Service (AKS).  AKS 带来了诸多优点, 如高可用的控制平面、Calico 等网络插件集成、Azure 服务无缝对接、与开源版本 Kubernetes 同步匹配、平滑迁移及无感知升级等。</p>
<p>在大数据处理与分析领域, 从技术的成熟度、稳定度以及社区活度程度来看, Apache Spark 是目前最流行的计算框架并在实际生产中处于重要地位并广泛使用. Apache Spark 支持 Standalone、Mesos 以及 YARN 等集群资源管理调度平台, 其中以 YARN 在实际生产中使用最为广泛, YARN 就是我们熟知的 Hadoop 平台的资源调度框架. 在计算存储不分离的架构下, 集群每个节点也会作为 Datanode 即采用 HDFS 分布式文件系统来进行数据存储. 但是随着数据量的爆炸式增长以及数据湖概念的日益普及, 计算与存储分离也逐渐成为了刚需. 为此, Microsoft Azure 也推出了满足以上需求的托管式 Hadoop 服务 —— Azure HDInsight 以及 Databricks. HDInsight 是 HDP 版本 Hadoop 在 Azure 云上的托管服务, Databricks 是著名 Spark 创始人完全基于 Apache Spark 并针对 Microsoft Azure 云服务平台进行优化的 Spark 托管服务.</p>
<p>目前最火热的两个技术已经可以结合并迸发出了新的火花, 2.3.0 版本以上的 Apache Spark 已经提供了对 Kubernetes 平台的支持与集成, 使我们能够利用原生的 Kubernetes 来进行集群计算资源的分配与管理 Spark 计算作业. 在该模式下, Spark Driver 和 Executor 都通过 Kubernetes Pods 来运行, 并且也可通过指定 Node Selector 将计算作业运行于特定节点之上 (例如: 带有GPU的实例类型等).<br>&lt;img src&#x3D;”<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/k8s-cluster-mode.jpg&quot;">https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/k8s-cluster-mode.jpg&quot;</a> “height:600px” width&#x3D;”600px” div align&#x3D;center&#x2F;&gt;<br>（from: <a target="_blank" rel="noopener" href="https://spark.apache.org/">https://spark.apache.org</a>).</p>
<h2 id="2-Apache-Spark-on-AKS-实现"><a href="#2-Apache-Spark-on-AKS-实现" class="headerlink" title="2. Apache Spark on AKS 实现"></a>2. Apache Spark on AKS 实现</h2><p>本实验需要正确安装 azcli, kubectl 等命令行工具, 详细步骤请参考相应文档, 本文不再赘述. 具体的操作过程在 AKS Vnet 的一台内网服务器的 root 家目录下进行, 该服务器作为 Spark 集群的 Gateway 客户端.</p>
<h3 id="2-1-创建-AKS-集群"><a href="#2-1-创建-AKS-集群" class="headerlink" title="2.1 创建 AKS 集群"></a>2.1 创建 AKS 集群</h3><h4 id="2-1-1-创建资源组"><a href="#2-1-1-创建资源组" class="headerlink" title="2.1.1 创建资源组"></a>2.1.1 创建资源组</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az group create --name akssparkrg --location southeastasia</span><br></pre></td></tr></table></figure>
<h4 id="2-1-2-创建-3-节点-AKS-集群"><a href="#2-1-2-创建-3-节点-AKS-集群" class="headerlink" title="2.1.2 创建 3 节点 AKS 集群"></a>2.1.2 创建 3 节点 AKS 集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">az aks create --resource-group akssparkrg \</span><br><span class="line">--name aksspark0001 \</span><br><span class="line">--kubernetes-version 1.14.7 \</span><br><span class="line">--node-count 3 \</span><br><span class="line">--node-vm-size Standard_DS2_v3 \</span><br><span class="line">--enable-addons monitoring \</span><br><span class="line">--admin-username akssparkuser \</span><br><span class="line">--ssh-key-value ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>
<p>集群创建时间在20分钟左右.</p>
<h4 id="2-1-3-获取-AKS-Credential"><a href="#2-1-3-获取-AKS-Credential" class="headerlink" title="2.1.3 获取 AKS Credential:"></a>2.1.3 获取 AKS Credential:</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az aks get-credentials --resource-group akssparkrg --name aksspark0001</span><br></pre></td></tr></table></figure>

<h3 id="2-2-在-AKS-集群中创建-Spark-服务帐户并绑定权限"><a href="#2-2-在-AKS-集群中创建-Spark-服务帐户并绑定权限" class="headerlink" title="2.2 在 AKS 集群中创建 Spark 服务帐户并绑定权限"></a>2.2 在 AKS 集群中创建 Spark 服务帐户并绑定权限</h3><h4 id="2-2-1-创建-Spark-服务账号"><a href="#2-2-1-创建-Spark-服务账号" class="headerlink" title="2.2.1 创建 Spark 服务账号"></a>2.2.1 创建 Spark 服务账号</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create serviceaccount spark</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-权限绑定"><a href="#2-2-2-权限绑定" class="headerlink" title="2.2.2 权限绑定"></a>2.2.2 权限绑定</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding spark-role \</span><br><span class="line">--clusterrole=edit \</span><br><span class="line">--serviceaccount=default:spark \</span><br><span class="line">--namespace=default</span><br></pre></td></tr></table></figure>

<h3 id="2-3-下载-Spark-二进制文件"><a href="#2-3-下载-Spark-二进制文件" class="headerlink" title="2.3 下载 Spark 二进制文件"></a>2.3 下载 Spark 二进制文件</h3><p>从 <a target="_blank" rel="noopener" href="http://spark.apache.org/downloads.html">Spark官网</a> 选择合适的版本下载, 本例中使用 2.4.4 版本 ( 需要高于2.3.0 ).</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz</span><br><span class="line">tar -zvxf spark-2.4.4-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure>

<h3 id="2-4-确认-Spark-Jar-和-Kubernetes-的版本兼容性"><a href="#2-4-确认-Spark-Jar-和-Kubernetes-的版本兼容性" class="headerlink" title="2.4 确认 Spark Jar 和 Kubernetes 的版本兼容性"></a>2.4 确认 Spark Jar 和 Kubernetes 的版本兼容性</h3><p>Spark 采用了 <a target="_blank" rel="noopener" href="https://github.com/fabric8io/kubernetes-client">fabric8.io</a> 的 Kubernetes &amp; OpenShift Java Client 客户端连接 API Server 来进行资源调度和分配, 需要先确认 Spark 2.4.4 自带的 kubernetes-client-*.jar 版本与 AKS 集群版本是否兼容. Spark 2.4.4 自带的 Kubernetes-client 版本为 4.1.2 ( kubernetes-client-4.1.2.jar ), AKS集群版本为 1.14.7, 存在版本不兼容问题，需要更高版本 jar 包. 具体的版本对应关系如下表所示:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">|                           | Kubernetes 1.4.9 | Kubernetes 1.6.0 | Kubernetes 1.7.0  | Kubernetes 1.9.0  | Kubernetes 1.10.0 | Kubernetes 1.11.0 | Kubernetes 1.12.0 | Kubernetes 1.14.2 | Kubernetes 1.15.3 |</span><br><span class="line">|---------------------------|------------------|------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|</span><br><span class="line">| kubernetes-client 1.3.92  | +                | +                | -                 | -                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 3.0.3   | -                | -                | ✓                 | -                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 3.0.10  | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 3.0.11  | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 3.1.12  | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 3.2.0   | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.0.0   | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.1.0   | -                | ✓                | ✓                 | ✓                 | -                 | -                 | -                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.1.1   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.1.2   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.1.3   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.2.0   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.2.1   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.2.2   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 | -                 |</span><br><span class="line">| kubernetes-client 4.3.0   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.3.1   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.4.0   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.4.1   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.4.2   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.5.0   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.5.1   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.5.2   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | -                 |</span><br><span class="line">| kubernetes-client 4.6.0   | -                | -                | -                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 | ✓                 |</span><br></pre></td></tr></table></figure>
<p>本文我们直接使用能够与 Kubernetes 1.14.7 版本兼容的 kubernetes-client 4.6.0.jar, 通过 <a target="_blank" rel="noopener" href="https://mvnrepository.com/artifact/io.fabric8/kubernetes-client">这里</a> 下载, 下载后替换 spark-2.4.4-bin-hadoop2.7&#x2F;jars 目录下的 kubernetes-client-4.1.2.jar 即可.</p>
<h3 id="2-5-创建-ACR-Azure-Container-Registry-并与-AKS-集成"><a href="#2-5-创建-ACR-Azure-Container-Registry-并与-AKS-集成" class="headerlink" title="2.5 创建 ACR (Azure Container Registry) 并与 AKS 集成"></a>2.5 创建 ACR (Azure Container Registry) 并与 AKS 集成</h3><h4 id="2-5-1-创建-ACR"><a href="#2-5-1-创建-ACR" class="headerlink" title="2.5.1 创建 ACR"></a>2.5.1 创建 ACR</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az acr create -n akssparkacr0001 -g akssparkrg --sku basic</span><br></pre></td></tr></table></figure>
<p><strong>记录 ACR Resource ID:</strong><br>&#x2F;subscriptions&#x2F;53a326cc-f961-4540-8701-2bfd1003242b&#x2F;resourceGroups&#x2F;akssparkrg&#x2F;providers&#x2F;Microsoft.ContainerRegistry&#x2F;registries&#x2F;akssparkacr0001</p>
<h4 id="2-5-2-ACR-与-AKS-集群集成"><a href="#2-5-2-ACR-与-AKS-集群集成" class="headerlink" title="2.5.2 ACR 与 AKS 集群集成"></a>2.5.2 ACR 与 AKS 集群集成</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">az aks update -n aksspark0001 -g akssparkrg --attach-acr akssparkacr0001</span><br><span class="line">az aks update -n aksspark0001 -g akssparkrg --attach-acr /subscriptions/53a326cc-f961-4540-8701-2bfd1003242b/resourceGroups/akssparkrg/providers/Microsoft.ContainerRegistry/registries/akssparkacr0001</span><br></pre></td></tr></table></figure>
<h4 id="2-5-3-登录-ACR"><a href="#2-5-3-登录-ACR" class="headerlink" title="2.5.3 登录 ACR"></a>2.5.3 登录 ACR</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">az acr login -n akssparkacr0001</span><br></pre></td></tr></table></figure>

<h3 id="2-6-构建-Spark-镜像"><a href="#2-6-构建-Spark-镜像" class="headerlink" title="2.6 构建 Spark 镜像"></a>2.6 构建 Spark 镜像</h3><h4 id="2-6-1-构建并推送镜像至-ACR"><a href="#2-6-1-构建并推送镜像至-ACR" class="headerlink" title="2.6.1 构建并推送镜像至 ACR"></a>2.6.1 构建并推送镜像至 ACR</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">REGISTRY_NAME=akssparkacr0001.azurecr.io</span><br><span class="line">REGISTRY_TAG=v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行脚本构建 Spark 镜像</span></span><br><span class="line">./bin/docker-image-tool.sh -r <span class="variable">$REGISTRY_NAME</span> -t <span class="variable">$REGISTRY_TAG</span> build</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送镜像</span></span><br><span class="line">./bin/docker-image-tool.sh -r <span class="variable">$REGISTRY_NAME</span> -t <span class="variable">$REGISTRY_TAG</span> push</span><br></pre></td></tr></table></figure>
<h4 id="2-6-2-Azure-查看docker-image"><a href="#2-6-2-Azure-查看docker-image" class="headerlink" title="2.6.2 Azure 查看docker image:"></a>2.6.2 Azure 查看docker image:</h4><p>&lt;img src&#x3D;”<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/ACR.jpg&quot;">https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/ACR.jpg&quot;</a> “height:1000px” width&#x3D;”1000px” div align&#x3D;center&#x2F;&gt;<br>通过 docker image list 也可以看, 自动构建了 Spark 原生, Spark-R 以及 Pyspark 的容器镜像.<br>&lt;img src&#x3D;”<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/DockerImage.jpg&quot;">https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/DockerImage.jpg&quot;</a> “height:1000px” width&#x3D;”1000px” div align&#x3D;center&#x2F;&gt;</p>
<h3 id="2-7-运行作业-SparkPi"><a href="#2-7-运行作业-SparkPi" class="headerlink" title="2.7 运行作业 SparkPi"></a>2.7 运行作业 SparkPi</h3><p>Spark 作业两种方式来运行, Cluster 和 Client 模式. 两种模式的主要区别简单概括就是 Spark Job Driver 是在本地节点还是集群节点上. 在实际生产过程中, 通常会将 spark-submit 的作业提交方式服务化, 通过外部服务调用将作业提交到集群上运行, 最典型的就是 Apache Livy. 本文采取通过命令行 spark-submit 将 SparkPi 作业提交到集群上计算的方式.</p>
<h4 id="2-7-1-创建-Storage-Account-并将-spark-examples-2-11-2-4-4-jar-上传至-Azure-Blob"><a href="#2-7-1-创建-Storage-Account-并将-spark-examples-2-11-2-4-4-jar-上传至-Azure-Blob" class="headerlink" title="2.7.1 创建 Storage Account 并将 spark-examples_2.11-2.4.4.jar 上传至 Azure Blob"></a>2.7.1 创建 Storage Account 并将 spark-examples_2.11-2.4.4.jar 上传至 Azure Blob</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变量定义, storage account name</span></span><br><span class="line">RESOURCE_GROUP=akssparkrg</span><br><span class="line">STORAGE_ACCT=akssparksa0001</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 storage account</span></span><br><span class="line">az group create --name <span class="variable">$RESOURCE_GROUP</span> --location southeastasia</span><br><span class="line">az storage account create --resource-group <span class="variable">$RESOURCE_GROUP</span> --name <span class="variable">$STORAGE_ACCT</span> --sku Standard_LRS</span><br><span class="line"><span class="built_in">export</span> AZURE_STORAGE_CONNECTION_STRING=`az storage account show-connection-string --resource-group <span class="variable">$RESOURCE_GROUP</span> --name <span class="variable">$STORAGE_ACCT</span> -o tsv`</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定上传 jar</span></span><br><span class="line">CONTAINER_NAME=akssparkjars</span><br><span class="line">BLOB_NAME=spark-examples_2.11-2.4.4.jar</span><br><span class="line">FILE_TO_UPLOAD=/root/aksspark/spark-2.4.4-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.4.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 blob container</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Creating the container...&quot;</span></span><br><span class="line">az storage container create --name <span class="variable">$CONTAINER_NAME</span></span><br><span class="line">az storage container set-permission --name <span class="variable">$CONTAINER_NAME</span> --public-access blob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传 jar</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Uploading the file...&quot;</span></span><br><span class="line">az storage blob upload --container-name <span class="variable">$CONTAINER_NAME</span> --file <span class="variable">$FILE_TO_UPLOAD</span> --name <span class="variable">$BLOB_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 jar url </span></span><br><span class="line">JARURL=$(az storage blob url --container-name <span class="variable">$CONTAINER_NAME</span> --name <span class="variable">$BLOB_NAME</span> | <span class="built_in">tr</span> -d <span class="string">&#x27;&quot;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-7-2-运行-SparkPi"><a href="#2-7-2-运行-SparkPi" class="headerlink" title="2.7.2 运行 SparkPi"></a>2.7.2 运行 SparkPi</h4><p>通过 spark-submit 提交 SparkPi 作业</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-2.4.4-bin-hadoop2.7</span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --master k8s://https://aksspark00-akssparkrg-53a326-07f35845.hcp.southeastasia.azmk8s.io:443 \ <span class="comment"># AKS 集群地址</span></span><br><span class="line">  --deploy-mode cluster \ <span class="comment"># 集群模式</span></span><br><span class="line">  --name spark-pi \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --conf spark.executor.instances=3 \ <span class="comment"># 申请 3 个 Executor</span></span><br><span class="line">  --conf spark.kubernetes.container.image=akssparkacr0001.azurecr.io/spark:v1 \ <span class="comment"># Docker Image 地址</span></span><br><span class="line">  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \ <span class="comment"># 指定创建的 Service Account spark</span></span><br><span class="line">  https://akssparksa0001.blob.core.windows.net/akssparkjars/spark-examples_2.11-2.4.4.jar <span class="comment"># Jar</span></span><br></pre></td></tr></table></figure>
<p>  spark-submit 的具体参数可以参考 <a target="_blank" rel="noopener" href="http://spark.apache.org/docs/latest/running-on-kubernetes.html">Spark on Kubernetes官网</a>, 不过官方文档只有默认参数配置. 如果需要看所有参数的可选值, 可以考虑去看 GitHub 上 <a target="_blank" rel="noopener" href="https://github.com/apache/spark/blob/master/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/Config.scala">Spark 源代码</a>.</p>
<h4 id="2-7-3-查看运行结果"><a href="#2-7-3-查看运行结果" class="headerlink" title="2.7.3 查看运行结果"></a>2.7.3 查看运行结果</h4><p>查看 Spark Job Driver 和对应的 Executor Pods</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@AKSSpark spark-2.4.4-bin-hadoop2.7]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">spark-pi-1571055145415-driver   1/1     Running   0          25s</span><br><span class="line">spark-pi-1571055145415-exec-1   1/1     Running   0          15s</span><br><span class="line">spark-pi-1571055145415-exec-2   1/1     Running   0          15s</span><br><span class="line">spark-pi-1571055145415-exec-3   0/1     Pending   0          15s</span><br></pre></td></tr></table></figure>
<p>运行作业时. 还可以访问 Spark UI. kubectl port-forward 命令提供对 Spark Job UI 的访问权限.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl port-forward spark-pi-1571055145415-driver 4040:4040</span><br></pre></td></tr></table></figure>
<p>&lt;img src&#x3D;”<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/Spark.jpg&quot;">https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/Spark.jpg&quot;</a> “height:1000px” width&#x3D;”1000px” div align&#x3D;center&#x2F;&gt;<br>获取作业结果和日志</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@AKSSpark spark-2.4.4-bin-hadoop2.7]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                                       READY   STATUS      RESTARTS   AGE</span><br><span class="line">spark-pi-1571055145415-driver              0/1     Completed   0          53s</span><br></pre></td></tr></table></figure>
<p>使用 kubectl logs 来获取 Spark 作业的 Log</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs spark-pi-1571055145415-driver</span><br></pre></td></tr></table></figure>
<p>日志中，可以看到 Spark 作业的结果，即 Pi 的值.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pi is roughly 3.1412957064785325</span><br></pre></td></tr></table></figure>

<h3 id="2-8-使用-Spark-Shell-进行交互式分析-Azure-Blob-数据"><a href="#2-8-使用-Spark-Shell-进行交互式分析-Azure-Blob-数据" class="headerlink" title="2.8 使用 Spark Shell 进行交互式分析 Azure Blob 数据"></a>2.8 使用 Spark Shell 进行交互式分析 Azure Blob 数据</h3><p>在很多需要调试的场景中, 都会通过命令行的交互式界面来进行调试. 对于 Spark 来说, 有 Spark Shell、Spark-R、Pyspark 三种命令行, 分别针对 Scala, R 以及 Python. 下面我们通过Spark Shell 来分析 Azure Blob 的数据.</p>
<h4 id="2-8-1-Docker-Image-新打包-v2-版本"><a href="#2-8-1-Docker-Image-新打包-v2-版本" class="headerlink" title="2.8.1 Docker Image 新打包 v2 版本"></a>2.8.1 Docker Image 新打包 v2 版本</h4><p>Spark 通过 wasbs:&#x2F;&#x2F;{container-name}@{storage-account-name}.blob.core.windows.net 访问 Azure Blob, 这需要在 Spark Jar 中加载 azure-storage.jar 和 hadoop-azure.jar, 这些 Jar 需要打在 Docker Image 里面, 然后上传至 ACR.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-2.4.4-bin-hadoop2.7/jars</span><br><span class="line">wget http://central.maven.org/maven2/com/microsoft/azure/azure-storage/2.2.0/azure-storage-2.2.0.jar</span><br><span class="line">wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.3/hadoop-azure-2.7.3.jar</span><br></pre></td></tr></table></figure>
<p>然后重复 2.6 节的操作, 指定版本号为 v2, 打包好后推送到 ACR 上, 具体的 Image 地址为 akssparkacr0001.azurecr.io&#x2F;spark:v2.</p>
<h4 id="2-8-2-使用-Spark-Shell-交互式分析-Azure-Blob-中的数据"><a href="#2-8-2-使用-Spark-Shell-交互式分析-Azure-Blob-中的数据" class="headerlink" title="2.8.2 使用 Spark Shell 交互式分析 Azure Blob 中的数据"></a>2.8.2 使用 Spark Shell 交互式分析 Azure Blob 中的数据</h4><p>运行 Spark Shell</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-2.4.4-bin-hadoop2.7</span><br><span class="line">./bin/spark-shell \</span><br><span class="line">  --master k8s://https://aksspark00-akssparkrg-53a326-07f35845.hcp.southeastasia.azmk8s.io:443 \</span><br><span class="line">  --name spark-shell \</span><br><span class="line">  --deploy-mode client \</span><br><span class="line">  --conf spark.executor.instances=3 \</span><br><span class="line">  --conf spark.kubernetes.executor.limit.cores=1 \</span><br><span class="line">  --conf spark.kubernetes.container.image=akssparkacr0001.azurecr.io/spark:v3</span><br></pre></td></tr></table></figure>
<p>进入 Spark Shell Scala 命令行交互界面<br>&lt;img src&#x3D;”<a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/SparkShell.jpg&quot;">https://cdn.jsdelivr.net/gh/TheoDoreW/CDN_Images@master/images/2019-10-13-SparkonAKS/SparkShell.jpg&quot;</a> “height:1000px” width&#x3D;”1000px” div align&#x3D;center&#x2F;&gt;</p>
<p>Scala 验证</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(1 to 100000).count</span><br><span class="line">res10: Long = 100000</span><br></pre></td></tr></table></figure>
<p>具体的分析的文件为示例 csv, 名为 diamonds.csv, 并已经提前上传到 Azure Blob Container 名为 sparkshell 中.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Azure Blob Storage Account 认证</span></span><br><span class="line">scala&gt; spark.conf.set(</span><br><span class="line">     |     <span class="string">&quot;fs.azure.account.key.akssparksa0001.blob.core.windows.net&quot;</span>,</span><br><span class="line">     |     <span class="string">&quot;gWfl5JezYzXs1ub572KZDAWTR9buVb/pb/dHj/iqsKV07fQKSl+JzUqcLWgx4Qr7xQTVPBSVsXhO6Aja/torAw==&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 blob 文件</span></span><br><span class="line">scala&gt; val diamonds = spark.read.format(<span class="string">&quot;csv&quot;</span>).option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>).option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>).load(<span class="string">&quot;wasbs://sparkshell@akssparksa0001.blob.core.windows.net/diamonds.csv&quot;</span>)</span><br><span class="line">diamonds: org.apache.spark.sql.DataFrame = [_c0: int, carat: double ... 9 more fields]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示字段类型</span></span><br><span class="line">scala&gt; diamonds.printSchema()</span><br><span class="line">root</span><br><span class="line"> |-- _c0: <span class="built_in">integer</span> (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- carat: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- <span class="built_in">cut</span>: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- color: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- clarity: string (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- depth: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- table: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- price: <span class="built_in">integer</span> (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- x: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- y: double (nullable = <span class="literal">true</span>)</span><br><span class="line"> |-- z: double (nullable = <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 显示前 10 行数据</span></span><br><span class="line">scala&gt; diamonds.show(10)</span><br><span class="line">+---+-----+---------+-----+-------+-----+-----+-----+----+----+----+            </span><br><span class="line">|_c0|carat|      <span class="built_in">cut</span>|color|clarity|depth|table|price|   x|   y|   z|</span><br><span class="line">+---+-----+---------+-----+-------+-----+-----+-----+----+----+----+</span><br><span class="line">|  1| 0.23|    Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|</span><br><span class="line">|  2| 0.21|  Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|</span><br><span class="line">|  3| 0.23|     Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|</span><br><span class="line">|  4| 0.29|  Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|</span><br><span class="line">|  5| 0.31|     Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|</span><br><span class="line">|  6| 0.24|Very Good|    J|   VVS2| 62.8| 57.0|  336|3.94|3.96|2.48|</span><br><span class="line">|  7| 0.24|Very Good|    I|   VVS1| 62.3| 57.0|  336|3.95|3.98|2.47|</span><br><span class="line">|  8| 0.26|Very Good|    H|    SI1| 61.9| 55.0|  337|4.07|4.11|2.53|</span><br><span class="line">|  9| 0.22|     Fair|    E|    VS2| 65.1| 61.0|  337|3.87|3.78|2.49|</span><br><span class="line">| 10| 0.23|Very Good|    H|    VS1| 59.4| 61.0|  338| 4.0|4.05|2.39|</span><br><span class="line">+---+-----+---------+-----+-------+-----+-----+-----+----+----+----+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取前 10 行并写入新文件</span></span><br><span class="line">scala&gt; diamonds.limit(10).write.format(<span class="string">&quot;csv&quot;</span>).save(<span class="string">&quot;wasbs://sparkshell@akssparksa0001.blob.core.windows.net/1.csv&quot;</span>)</span><br><span class="line">scala&gt; spark.read.csv(<span class="string">&quot;wasbs://sparkshell@akssparksa0001.blob.core.windows.net/1.csv&quot;</span>).show()</span><br><span class="line">+---+----+---------+---+----+----+----+---+----+----+----+</span><br><span class="line">|_c0| _c1|      _c2|_c3| _c4| _c5| _c6|_c7| _c8| _c9|_c10|</span><br><span class="line">+---+----+---------+---+----+----+----+---+----+----+----+</span><br><span class="line">|  1|0.23|    Ideal|  E| SI2|61.5|55.0|326|3.95|3.98|2.43|</span><br><span class="line">|  2|0.21|  Premium|  E| SI1|59.8|61.0|326|3.89|3.84|2.31|</span><br><span class="line">|  3|0.23|     Good|  E| VS1|56.9|65.0|327|4.05|4.07|2.31|</span><br><span class="line">|  4|0.29|  Premium|  I| VS2|62.4|58.0|334| 4.2|4.23|2.63|</span><br><span class="line">|  5|0.31|     Good|  J| SI2|63.3|58.0|335|4.34|4.35|2.75|</span><br><span class="line">|  6|0.24|Very Good|  J|VVS2|62.8|57.0|336|3.94|3.96|2.48|</span><br><span class="line">|  7|0.24|Very Good|  I|VVS1|62.3|57.0|336|3.95|3.98|2.47|</span><br><span class="line">|  8|0.26|Very Good|  H| SI1|61.9|55.0|337|4.07|4.11|2.53|</span><br><span class="line">|  9|0.22|     Fair|  E| VS2|65.1|61.0|337|3.87|3.78|2.49|</span><br><span class="line">| 10|0.23|Very Good|  H| VS1|59.4|61.0|338| 4.0|4.05|2.39|</span><br><span class="line">+---+----+---------+---+----+----+----+---+----+----+----+</span><br></pre></td></tr></table></figure>
<p>另外, 跨 Azure Blob Container 的文件读写也可以.</p>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>通过以上的几个步骤, 可以实现在 Azure Kubernetes Service 集群上运行 Spark 作业的平台部署. 与传统的 YARN 来做资源管理调度相比较而言更为轻量快捷, 同时可以与 Azure Blob 做集成, 数据存储在 Azure Blob 中进行分析, 既可以保证数据高可靠性也能够实现计算与存储的分离从而提高灵活性.</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="https://theodorew.github.io/wxsblog.github.io/2019/10/13/2019-10-13-SparkonAKS/" data-id="claq92fmf00019nxz4oxf7mwl" class="article-share-link" data-share="baidu" data-title="强强联合! 利用 Microsoft Azure AKS 集群集成 Apache Spark 来做大数据计算">Share</a>
      

      

      
        <a class="article-reward-link">Reward</a>
      

      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/wxsblog.github.io/tags/Bigdata/" rel="tag">Bigdata</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/wxsblog.github.io/tags/Kubernetes/" rel="tag">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/wxsblog.github.io/tags/Linux/" rel="tag">Linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/wxsblog.github.io/tags/Microsoft-Azure/" rel="tag">Microsoft Azure</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/wxsblog.github.io/2019/11/17/2019-11-18-FlinkonAKS/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          新一代大数据计算框架 Flink 与 Microsoft Azure Kubernetes 集成来做流批计算
        
      </div>
    </a>
  
  
    <a href="/wxsblog.github.io/2019/01/18/2019-01-18-WSL/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Win10强大的WSL(Windows Subsystem for Linux)</div>
    </a>
  
</nav>

  
</article>


</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Linux/">Linux</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Linux/Windows-10/">Windows 10</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Linux/Windows-10/WSL/">WSL</a><span class="category-list-count">1</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/">Microsoft Azure</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Database/">Database</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Database/MySQL/">MySQL</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Database/MySQL/Linux/">Linux</a><span class="category-list-count">1</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Databricks/">Databricks</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Databricks/Bigdata/">Bigdata</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Databricks/Bigdata/Linux/">Linux</a><span class="category-list-count">4</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Github/">Github</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Github/CDN/">CDN</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Github/CDN/Linux/">Linux</a><span class="category-list-count">2</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/">Kubernetes</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/">Bigdata</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/Flink/">Flink</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/Flink/Linux/">Linux</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Kubernetes/Bigdata/Linux/">Linux</a><span class="category-list-count">1</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/">Monitor</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/MongoDB/">MongoDB</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/MongoDB/Linux/">Linux</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/SNMP/">SNMP</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/SNMP/Linux/">Linux</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/Monitor/SNMP/Linux/Fortigate/">Fortigate</a><span class="category-list-count">1</span></li></ul></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/infrastructure/">infrastructure</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/infrastructure/Linux/">Linux</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/infrastructure/Linux/Automation/">Automation</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/wxsblog.github.io/categories/Microsoft-Azure/infrastructure/Linux/DataBase/">DataBase</a><span class="category-list-count">1</span></li></ul></li></ul></li></ul></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Automation/" rel="tag">Automation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Bigdata/" rel="tag">Bigdata</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/CDN/" rel="tag">CDN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/DataBase/" rel="tag">DataBase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Database/" rel="tag">Database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Databricks/" rel="tag">Databricks</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Flink/" rel="tag">Flink</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Fortigate/" rel="tag">Fortigate</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Github/" rel="tag">Github</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Kubernetes/" rel="tag">Kubernetes</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Microsoft-Azure/" rel="tag">Microsoft Azure</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/MongoDB/" rel="tag">MongoDB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Monitor/" rel="tag">Monitor</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/MySQL/" rel="tag">MySQL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/SNMP/" rel="tag">SNMP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/WSL/" rel="tag">WSL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/Windows-10/" rel="tag">Windows 10</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/wxsblog.github.io/tags/infrastructure/" rel="tag">infrastructure</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/wxsblog.github.io/tags/Automation/" style="font-size: 11.67px;">Automation</a> <a href="/wxsblog.github.io/tags/Bigdata/" style="font-size: 16.67px;">Bigdata</a> <a href="/wxsblog.github.io/tags/CDN/" style="font-size: 11.67px;">CDN</a> <a href="/wxsblog.github.io/tags/DataBase/" style="font-size: 10px;">DataBase</a> <a href="/wxsblog.github.io/tags/Database/" style="font-size: 10px;">Database</a> <a href="/wxsblog.github.io/tags/Databricks/" style="font-size: 15px;">Databricks</a> <a href="/wxsblog.github.io/tags/Flink/" style="font-size: 10px;">Flink</a> <a href="/wxsblog.github.io/tags/Fortigate/" style="font-size: 10px;">Fortigate</a> <a href="/wxsblog.github.io/tags/Github/" style="font-size: 11.67px;">Github</a> <a href="/wxsblog.github.io/tags/Kubernetes/" style="font-size: 11.67px;">Kubernetes</a> <a href="/wxsblog.github.io/tags/Linux/" style="font-size: 20px;">Linux</a> <a href="/wxsblog.github.io/tags/Microsoft-Azure/" style="font-size: 18.33px;">Microsoft Azure</a> <a href="/wxsblog.github.io/tags/MongoDB/" style="font-size: 10px;">MongoDB</a> <a href="/wxsblog.github.io/tags/Monitor/" style="font-size: 11.67px;">Monitor</a> <a href="/wxsblog.github.io/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/wxsblog.github.io/tags/SNMP/" style="font-size: 10px;">SNMP</a> <a href="/wxsblog.github.io/tags/WSL/" style="font-size: 10px;">WSL</a> <a href="/wxsblog.github.io/tags/Windows-10/" style="font-size: 10px;">Windows 10</a> <a href="/wxsblog.github.io/tags/infrastructure/" style="font-size: 13.33px;">infrastructure</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2022/11/">November 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2021/07/">July 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2021/03/">March 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2020/12/">December 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2020/11/">November 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2020/09/">September 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2020/01/">January 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2019/12/">December 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2019/10/">October 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/wxsblog.github.io/archives/2019/01/">January 2019</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/wxsblog.github.io/2022/11/11/2022-11-11-AzureMySQLFlexibleServerNetworking/">Azure MySQL Flexible Server 内网 DNS 集成方案blog</a>
          </li>
        
          <li>
            <a href="/wxsblog.github.io/2021/07/26/2021-07-26-AzureImageBuilderCLSIGI/">Azure Image Builder（二）之自动化构建自定义托管镜像 CentOS 7.7 并集成 Azure Shared Image Gallery 做全球分发</a>
          </li>
        
          <li>
            <a href="/wxsblog.github.io/2021/07/25/2021-07-25-AzureImageBuilderCLMI/">Azure Image Builder（一）之自动化构建自定义托管镜像 CentOS 7.7</a>
          </li>
        
          <li>
            <a href="/wxsblog.github.io/2021/03/17/2021-03-17-AzureDatabricksMonitor/">Azure Databricks 系列 Blog（四）之通过 Azure Monitor 做集群监控</a>
          </li>
        
          <li>
            <a href="/wxsblog.github.io/2020/12/17/2020-12-17-AzureDatabricksSparkSQLonDeltaLake/">Azure Databricks 系列 Blog（三）之 SparkSQL on Delta Lake</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="http://arvinxiang.com" target="_blank">主题作者</a>
          </li>
        
          <li>
            <a href="http://reqianduan.com" target="_blank">热前端</a>
          </li>
        
          <li>
            <a href="http://yuancheng.work" target="_blank">远程.work</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Xinsheng Wang<br>
 
      <span id="busuanzi_container_site_pv">
      本站总访问量<span id="busuanzi_value_site_pv"></span>次
      </span>
      <span id="busuanzi_container_site_uv">
      本站访客数<span id="busuanzi_value_site_uv"></span>人次
      </span>

      <br>
      Powered by <a href="//hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>
    </div>
  </div>
</footer>

  </div>
  <nav id="mobile-nav">
  
    <a href="/wxsblog.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="/wxsblog.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="totop"><img src="/wxsblog.github.io/img/scrollup.png"/></a>
</div>

<!-- totop end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/wxsblog.github.io/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>





<script src="/wxsblog.github.io/js/script.js"></script>


</div>
</body>
</html>
